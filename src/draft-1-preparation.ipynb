{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88117ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/arthur/Documents/Universite/M2-QEA/Machine Learning/final_project/ml_project\n",
      "✓ Datasets loaded: main_df(50044, 10), sport_df(6460, 2), job_df(19336, 11), job_security_df(24224, 2), retired_former_df(13176, 4), retired_jobs_df(11226, 11), retired_pension_df(11226, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set project root to ml_project directory\n",
    "if os.getcwd().endswith('src'):\n",
    "    os.chdir('..')\n",
    "    \n",
    "project_root = os.getcwd()\n",
    "print(f\"Working directory: {project_root}\")\n",
    "\n",
    "# Load datasets\n",
    "main_df = pd.read_csv(\"data/learn_dataset.csv\")\n",
    "sport_df = pd.read_csv(\"data/learn_dataset_sport.csv\")\n",
    "job_df = pd.read_csv(\"data/learn_dataset_job.csv\")\n",
    "job_security_df = pd.read_csv(\"data/learn_dataset_JOB_SECURITY.csv\")\n",
    "retired_former_df = pd.read_csv(\"data/learn_dataset_retired_former.csv\")\n",
    "retired_jobs_df = pd.read_csv(\"data/learn_dataset_retired_jobs.csv\")\n",
    "retired_pension_df = pd.read_csv(\"data/learn_dataset_retired_pension.csv\")\n",
    "\n",
    "print(f\"✓ Datasets loaded: main_df{main_df.shape}, sport_df{sport_df.shape}, job_df{job_df.shape}, job_security_df{job_security_df.shape}, retired_former_df{retired_former_df.shape}, retired_jobs_df{retired_jobs_df.shape}, retired_pension_df{retired_pension_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4188ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial main_df shape: (50044, 10)\n",
      "After merging sport_df: (50044, 11)\n",
      "After merging job_df: (50044, 21)\n",
      "After merging job_security_df: (50044, 22)\n",
      "After merging retired_former_df: (50044, 25)\n",
      "After merging retired_jobs_df: (50044, 26)\n",
      "After merging retired_pension_df: (50044, 27)\n",
      "\n",
      "✓ Final merged dataframe shape: (50044, 27)\n",
      "✓ Total columns: 27\n"
     ]
    }
   ],
   "source": [
    "# Function to merge and combine overlapping columns\n",
    "def merge_and_combine(left_df, right_df, on='primary_key'):\n",
    "    # Find overlapping columns (excluding the merge key)\n",
    "    overlap_cols = [col for col in left_df.columns if col in right_df.columns and col != on]\n",
    "    \n",
    "    # Merge with suffixes\n",
    "    merged = left_df.merge(right_df, on=on, how='left', suffixes=('', '_new'))\n",
    "    \n",
    "    # Combine overlapping columns (fill NaN in original with values from new)\n",
    "    for col in overlap_cols:\n",
    "        if col in merged.columns and f'{col}_new' in merged.columns:\n",
    "            merged[col] = merged[col].fillna(merged[f'{col}_new'])\n",
    "            merged.drop(f'{col}_new', axis=1, inplace=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Merge all dataframes to main_df using primary_key\n",
    "print(f\"Initial main_df shape: {main_df.shape}\")\n",
    "\n",
    "# Merge sport data\n",
    "main_df = merge_and_combine(main_df, sport_df)\n",
    "print(f\"After merging sport_df: {main_df.shape}\")\n",
    "\n",
    "# Merge job data\n",
    "main_df = merge_and_combine(main_df, job_df)\n",
    "print(f\"After merging job_df: {main_df.shape}\")\n",
    "\n",
    "# Merge job security data\n",
    "main_df = merge_and_combine(main_df, job_security_df)\n",
    "print(f\"After merging job_security_df: {main_df.shape}\")\n",
    "\n",
    "# Merge retired former data\n",
    "main_df = merge_and_combine(main_df, retired_former_df)\n",
    "print(f\"After merging retired_former_df: {main_df.shape}\")\n",
    "\n",
    "# Merge retired jobs data\n",
    "main_df = merge_and_combine(main_df, retired_jobs_df)\n",
    "print(f\"After merging retired_jobs_df: {main_df.shape}\")\n",
    "\n",
    "# Merge retired pension data\n",
    "main_df = merge_and_combine(main_df, retired_pension_df)\n",
    "print(f\"After merging retired_pension_df: {main_df.shape}\")\n",
    "\n",
    "print(f\"\\n✓ Final merged dataframe shape: {main_df.shape}\")\n",
    "print(f\"✓ Total columns: {len(main_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bb604",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m cols_to_encode = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols \u001b[38;5;28;01mif\u001b[39;00m main_df[col].nunique() < \u001b[32m50\u001b[39m]\n\u001b[32m      6\u001b[39m cols_to_drop = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols \u001b[38;5;28;01mif\u001b[39;00m main_df[col].nunique() >= \u001b[32m50\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns to encode (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cols_to_encode)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcols_to_encode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns to drop (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cols_to_drop)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcols_to_drop.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Drop high-cardinality categorical columns\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables with less than 50 distinct values\n",
    "categorical_cols = main_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Separate categorical columns by number of distinct values\n",
    "cols_to_encode = [col for col in categorical_cols if main_df[col].nunique() < 50]\n",
    "cols_to_drop = [col for col in categorical_cols if main_df[col].nunique() >= 50]\n",
    "\n",
    "print(f\"Columns to encode ({len(cols_to_encode)}): {cols_to_encode}\")\n",
    "print(f\"Columns to drop ({len(cols_to_drop)}): {cols_to_drop}\")\n",
    "\n",
    "# Drop high-cardinality categorical columns\n",
    "main_df = main_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# One-hot encode the remaining categorical columns\n",
    "main_df = pd.get_dummies(main_df, columns=cols_to_encode, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4922b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_pickle(\"data/merged_learn_dataset.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dauphine-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
