{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88117ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/arthur/Documents/Universite/M2-QEA/Machine Learning/final_project/ml_project\n",
      "✓ Datasets loaded: main_df(50044, 10), sport_df(6460, 2), job_df(19336, 11), job_security_df(24224, 2), retired_former_df(13176, 4), retired_jobs_df(11226, 11), retired_pension_df(11226, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set project root to ml_project directory\n",
    "if os.getcwd().endswith('src'):\n",
    "    os.chdir('..')\n",
    "    \n",
    "project_root = os.getcwd()\n",
    "print(f\"Working directory: {project_root}\")\n",
    "\n",
    "# Load datasets\n",
    "main_df = pd.read_csv(\"data/learn_dataset.csv\")\n",
    "sport_df = pd.read_csv(\"data/learn_dataset_sport.csv\")\n",
    "job_df = pd.read_csv(\"data/learn_dataset_job.csv\")\n",
    "job_security_df = pd.read_csv(\"data/learn_dataset_JOB_SECURITY.csv\")\n",
    "retired_former_df = pd.read_csv(\"data/learn_dataset_retired_former.csv\")\n",
    "retired_jobs_df = pd.read_csv(\"data/learn_dataset_retired_jobs.csv\")\n",
    "retired_pension_df = pd.read_csv(\"data/learn_dataset_retired_pension.csv\")\n",
    "job_desc_map_df = pd.read_csv(\"data/code_job_desc_map.csv\")\n",
    "departments_df = pd.read_csv(\"data/departments.csv\")\n",
    "sports_desc_df = pd.read_csv(\"data/code_Sports.csv\")\n",
    "city_pop_df = pd.read_csv(\"data/city_pop.csv\")\n",
    "# city_revenue_df = pd.read_csv(\"data/city_revenue.csv\", sep=';')\n",
    "\n",
    "print(f\"✓ Datasets loaded: main_df{main_df.shape}, sport_df{sport_df.shape}, job_df{job_df.shape}, job_security_df{job_security_df.shape}, retired_former_df{retired_former_df.shape}, retired_jobs_df{retired_jobs_df.shape}, retired_pension_df{retired_pension_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial main_df shape: (50044, 10)\n",
      "After merging sport_df: (50044, 11)\n",
      "After merging job_df: (50044, 21)\n",
      "After merging job_security_df: (50044, 22)\n",
      "After merging retired_former_df: (50044, 25)\n",
      "After merging retired_jobs_df: (50044, 26)\n",
      "After merging retired_pension_df: (50044, 27)\n",
      "\n",
      "✓ Final merged dataframe shape: (50044, 40)\n",
      "✓ Total columns: 40\n"
     ]
    }
   ],
   "source": [
    "# Function to merge and combine overlapping columns\n",
    "def merge_and_combine(left_df, right_df, on='primary_key'):\n",
    "    # Find overlapping columns (excluding the merge key)\n",
    "    overlap_cols = [col for col in left_df.columns if col in right_df.columns and col != on]\n",
    "    \n",
    "    # Merge with suffixes\n",
    "    merged = left_df.merge(right_df, on=on, how='left', suffixes=('', '_new'))\n",
    "    \n",
    "    # Combine overlapping columns (fill NaN in original with values from new)\n",
    "    for col in overlap_cols:\n",
    "        if col in merged.columns and f'{col}_new' in merged.columns:\n",
    "            merged[col] = merged[col].fillna(merged[f'{col}_new'])\n",
    "            merged.drop(f'{col}_new', axis=1, inplace=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# Merge all dataframes to main_df using primary_key\n",
    "print(f\"Initial main_df shape: {main_df.shape}\")\n",
    "\n",
    "# Merge sport data\n",
    "main_df = merge_and_combine(main_df, sport_df)\n",
    "print(f\"After merging sport_df: {main_df.shape}\")\n",
    "\n",
    "# Merge job data\n",
    "main_df = merge_and_combine(main_df, job_df)\n",
    "print(f\"After merging job_df: {main_df.shape}\")\n",
    "\n",
    "# Merge job security data\n",
    "main_df = merge_and_combine(main_df, job_security_df)\n",
    "print(f\"After merging job_security_df: {main_df.shape}\")\n",
    "\n",
    "# Merge retired former data\n",
    "main_df = merge_and_combine(main_df, retired_former_df)\n",
    "print(f\"After merging retired_former_df: {main_df.shape}\")\n",
    "\n",
    "# Merge retired jobs data\n",
    "main_df = merge_and_combine(main_df, retired_jobs_df)\n",
    "print(f\"After merging retired_jobs_df: {main_df.shape}\")\n",
    "\n",
    "# Merge retired pension data\n",
    "main_df = merge_and_combine(main_df, retired_pension_df)\n",
    "print(f\"After merging retired_pension_df: {main_df.shape}\")\n",
    "\n",
    "# Merge Job description mapping\n",
    "main_df = main_df.merge(job_desc_map_df, left_on='job_desc', right_on='N3', how='left')\n",
    "main_df = main_df.merge(sports_desc_df, left_on='Sports', right_on='Code', how='left')\n",
    "main_df = main_df.merge(city_pop_df, left_on='Insee_code', right_on='Insee_code', how='left')\n",
    "\n",
    "# # Clean city_revenue_df column names and values\n",
    "# city_revenue_df = city_revenue_df.rename(columns=lambda x: x.strip().split()[0])\n",
    "# # Convert all columns except the key column to numeric, replacing 'N/A - secret statistique' with NaN\n",
    "# for col in city_revenue_df.columns:\n",
    "#     if col != 'Code':  # Keep the Code column as is (assuming it's the key)\n",
    "#         city_revenue_df[col] = pd.to_numeric(city_revenue_df[col].replace('N/A - secret statistique', np.nan), errors='coerce')\n",
    "\n",
    "# main_df = main_df.merge(city_revenue_df, left_on='Insee_code', right_on='Code', how='left')\n",
    "\n",
    "main_df['dept'] = main_df['Insee_code'].str[:2]\n",
    "#main_df = main_df.merge(departments_df, left_on='dept', right_on='Dep', how='left')\n",
    "\n",
    "print(f\"\\n✓ Final merged dataframe shape: {main_df.shape}\")\n",
    "print(f\"✓ Total columns: {len(main_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be7bb604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to encode (23): ['activity_type', 'sex', 'Household', 'Occupation_42', 'HIGHEST_DIPLOMA', 'Sports', 'Work_condition', 'terms_of_emp', 'OCCUPATIONAL_STATUS', 'ECONOMIC_SECTOR', 'EMPLOYER_TYPE', 'Job_dep', 'Employee_count', 'JOB_SECURITY', 'Previous_occupation_42', 'PREVIOUS_JOB_SECURITY', 'Previous_dep', 'N2', 'N1', 'Code_x', 'Nom fédération', 'Nom catégorie', 'dept']\n",
      "Columns to drop (4): ['Insee_code', 'job_desc', 'N3', 'Code_y']\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables with less than 50 distinct values\n",
    "categorical_cols = main_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Separate categorical columns by number of distinct values\n",
    "cols_to_encode = [col for col in categorical_cols if main_df[col].nunique() < 100]\n",
    "cols_to_drop = [col for col in categorical_cols if main_df[col].nunique() >= 100]\n",
    "\n",
    "print(f\"Columns to encode ({len(cols_to_encode)}): {cols_to_encode}\")\n",
    "print(f\"Columns to drop ({len(cols_to_drop)}): {cols_to_drop}\")\n",
    "\n",
    "# Drop high-cardinality categorical columns\n",
    "main_df_dummies = main_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# One-hot encode the remaining categorical columns\n",
    "main_df_dummies = pd.get_dummies(main_df_dummies, columns=cols_to_encode, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4922b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df_dummies.to_pickle(\"data/merged_learn_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d623c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TESTING SIMPLE MERGE WITHOUT COMBINING OVERLAPPING COLUMNS ##\n",
    "\n",
    "# # Simple merge without combining overlapping columns\n",
    "# simple_df = main_df.copy()\n",
    "\n",
    "# print(f\"Initial shape: {simple_df.shape}\")\n",
    "\n",
    "# # Simple left merge with sport data\n",
    "# simple_df = simple_df.merge(sport_df, on='primary_key', how='left', suffixes=('', '_sport'))\n",
    "# print(f\"After merging sport_df: {simple_df.shape}\")\n",
    "\n",
    "# # Simple left merge with job data\n",
    "# simple_df = simple_df.merge(job_df, on='primary_key', how='left', suffixes=('', '_job'))\n",
    "# print(f\"After merging job_df: {simple_df.shape}\")\n",
    "\n",
    "# # Simple left merge with job security data\n",
    "# simple_df = simple_df.merge(job_security_df, on='primary_key', how='left', suffixes=('', '_security'))\n",
    "# print(f\"After merging job_security_df: {simple_df.shape}\")\n",
    "\n",
    "# # Simple left merge with retired former data\n",
    "# simple_df = simple_df.merge(retired_former_df, on='primary_key', how='left', suffixes=('', '_former'))\n",
    "# print(f\"After merging retired_former_df: {simple_df.shape}\")\n",
    "\n",
    "# # Simple left merge with retired jobs data\n",
    "# simple_df = simple_df.merge(retired_jobs_df, on='primary_key', how='left', suffixes=('', '_retjobs'))\n",
    "# print(f\"After merging retired_jobs_df: {simple_df.shape}\")\n",
    "\n",
    "# # Simple left merge with retired pension data\n",
    "# simple_df = simple_df.merge(retired_pension_df, on='primary_key', how='left', suffixes=('', '_pension'))\n",
    "# print(f\"After merging retired_pension_df: {simple_df.shape}\")\n",
    "\n",
    "# print(f\"\\n✓ Final simple merged shape: {simple_df.shape}\")\n",
    "# print(f\"✓ Overlapping columns will have suffixes (_sport, _job, etc.)\")\n",
    "\n",
    "# # One-hot encode categorical variables with less than 50 distinct values\n",
    "# categorical_cols = simple_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# # Separate categorical columns by number of distinct values\n",
    "# cols_to_encode = [col for col in categorical_cols if simple_df[col].nunique() < 50]\n",
    "# cols_to_drop = [col for col in categorical_cols if simple_df[col].nunique() >= 50]\n",
    "# print(f\"Columns to encode ({len(cols_to_encode)}): {cols_to_encode}\")\n",
    "# print(f\"Columns to drop ({len(cols_to_drop)}): {cols_to_drop}\")\n",
    "\n",
    "# # Drop high-cardinality categorical columns\n",
    "# simple_df = simple_df.drop(columns=cols_to_drop)\n",
    "\n",
    "# # One-hot encode the remaining categorical columns\n",
    "# simple_df = pd.get_dummies(simple_df, columns=cols_to_encode, drop_first=True)\n",
    "\n",
    "# simple_df.to_pickle(\"data/simple_merged_learn_dataset.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dauphine-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
